{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. imports, functions and variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   sentence_id  token_id        before\n",
      "0            0         0           Эта\n",
      "1            0         1         книга\n",
      "2            0         2             ,\n",
      "3            0         3  отличающаяся\n",
      "4            0         4             «\n",
      "        sentence_id  token_id     before\n",
      "989875        69999        17     убедил\n",
      "989876        69999        18        его\n",
      "989877        69999        19  выполнить\n",
      "989878        69999        20     приказ\n",
      "989879        69999        21          .\n",
      "175991\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import operator\n",
    "import gc\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from random import *\n",
    "import pickle\n",
    "import csv\n",
    "import re\n",
    "from num2words import num2words\n",
    "from transliterate import translit\n",
    "\n",
    "INPUT_PATH = r'./input'\n",
    "DATA_INPUT_PATH = r'./input/ru_with_types'\n",
    "SUBM_PATH = INPUT_PATH\n",
    "\n",
    "ch = {\"0\":\"ноль\",\n",
    "      \"1\":\"один\",\n",
    "      \"2\":\"два\",\n",
    "      \"3\":\"три\",\n",
    "      \"4\":\"четыре\",\n",
    "      \"5\":\"пять\",\n",
    "      \"6\":\"шесть\",\n",
    "      \"7\":\"семь\",\n",
    "      \"8\":\"восемь\",\n",
    "      \"9\":\"девять\"\n",
    "     }\n",
    "\n",
    "SUB = str.maketrans(\"₀₁₂₃₄₅₆₇₈₉\", \"0123456789\")\n",
    "SUP = str.maketrans(\"⁰¹²³⁴⁵⁶⁷⁸⁹\", \"0123456789\")\n",
    "\n",
    "punct = {'«','.','»',','}\n",
    "dash = {'-','—'}\n",
    "short = {\"по\",\"англ\",\"ее\",\"что\",\"есть\",\"где\",\"кто\",\"две\",\"ибн\",\"ту\"}\n",
    "\n",
    "res_new = dict()\n",
    "\n",
    "full = {\"проверено\",\"архивировано\", \"с\", \"от\", \"умер\", \"родился\", \"первоисточника\"}\n",
    "space = {\"на\",\"по\"} \n",
    "\n",
    "m = {}\n",
    "m['км²'] = 'квадратных километров'\n",
    "m['км2'] = 'квадратных километров'\n",
    "m['km²'] = 'квадратных километров'\n",
    "m['км'] = 'километрах'\n",
    "m['km'] = 'километрах'\n",
    "m['кг'] = 'килограмма'\n",
    "m['kg'] = 'килограмма'\n",
    "m['m²'] = 'квадратных метров'\n",
    "m['м²'] = 'квадратных метров'\n",
    "m['м³'] = 'кубических метров'\n",
    "m[\"млн\"] = \"миллионов\" \n",
    "m[\"м/с\"] = \"метров в секунду\"\n",
    "m[\"мм\"] = \"миллиметров\"\n",
    "m[\"м\"] = \"метров\"\n",
    "m[\"ч\"] = \"часов\"\n",
    "m[\"л\"] = \"лет\"\n",
    "m[\"тыс\"] = \"тысяч\"\n",
    "m[\"тонн\"] = \"тонн\"\n",
    "m[\"га\"] = \"гектара\"\n",
    "m[\"гг\"] = \"годы\"\n",
    "m[\"млрд\"] = \"миллиардов\"\n",
    "m[\"км/ч\"] = \"километров в час\"\n",
    "m[\"руб\"] = \"рублей\"\n",
    "m[\"с\"] = \"секунд\"\n",
    "m[\"м3\"] = \"кубических метров\"\n",
    "m[\"н. э.\"] = \"нашей эры\"\n",
    "m[\"трлн\"] = \"триллионов\"\n",
    "m[\"$\"] = \"долларов сэ ш а\"\n",
    "m[\"€\"] = \"евро\"\n",
    "m[\"%\"] = \"процентов\"\n",
    "m[\"долл\"] = \"долларов\"\n",
    "m[\"ГВт\"] = \"гигаватт\"\n",
    "m[\"МВт\"] = \"мегаватт\"\n",
    "m[\"кВт\"] = \"киловатт\"\n",
    "m[\"куб.см\"] = \"кубических сантиметров\"\n",
    "m[\"мкм\"] = \"микрометров\"\n",
    "m[\"об/мин\"] = \"оборотов в минуту\"\n",
    "m[\"нм\"] = \"нанометра\"\n",
    "\n",
    "mm = {\"1\":\"января\",\n",
    "      \"2\":\"февраля\",\n",
    "      \"3\":\"марта\",\n",
    "      \"4\":\"апреля\",\n",
    "      \"5\":\"мая\",\n",
    "      \"6\":\"июня\",\n",
    "      \"7\":\"июля\",\n",
    "      \"8\":\"августа\",\n",
    "      \"9\":\"сентября\",\n",
    "      \"10\":\"октября\",\n",
    "      \"11\":\"ноября\",\n",
    "      \"12\":\"декабря\",\n",
    "      \"01\":\"января\",\n",
    "      \"02\":\"февраля\",\n",
    "      \"03\":\"марта\",\n",
    "      \"04\":\"апреля\",\n",
    "      \"05\":\"мая\",\n",
    "      \"06\":\"июня\",\n",
    "      \"07\":\"июля\",\n",
    "      \"08\":\"августа\",\n",
    "      \"09\":\"сентября\"      \n",
    "     }\n",
    "\n",
    "d = {\"0\":\"\",\n",
    "     \"1\":\"первого\",\n",
    "     \"2\":\"второго\",\n",
    "     \"3\":\"третьего\",\n",
    "     \"4\":\"четвертого\",\n",
    "     \"5\":\"пятого\",\n",
    "     \"6\":\"шестого\",\n",
    "     \"7\":\"седьмого\",\n",
    "     \"8\":\"восьмого\",\n",
    "     \"9\":\"девятого\",\n",
    "     \"01\":\"первого\",\n",
    "     \"02\":\"второго\",\n",
    "     \"03\":\"третьего\",\n",
    "     \"04\":\"четвертого\",\n",
    "     \"05\":\"пятого\",\n",
    "     \"06\":\"шестого\",\n",
    "     \"07\":\"седьмого\",\n",
    "     \"08\":\"восьмого\",\n",
    "     \"09\":\"девятого\",\n",
    "     \"10\":\"десятого\",\n",
    "     \"11\":\"одиннадцатого\",\n",
    "     \"12\":\"двенадцатого\",\n",
    "     \"13\":\"тринадцатого\",\n",
    "     \"14\":\"четырнадцатого\",\n",
    "     \"15\":\"пятнадцатого\",\n",
    "     \"16\":\"шестнадцатого\",\n",
    "     \"17\":\"семнадцатого\",\n",
    "     \"18\":\"восемнадцатого\",\n",
    "     \"19\":\"девятнадцатого\",\n",
    "     \"20\":\"двадцатого\",\n",
    "     \"21\":\"двадцать первого\",\n",
    "     \"22\":\"двадцать второго\",\n",
    "     \"23\":\"двадцать третьего\",\n",
    "     \"24\":\"двадцать четвертого\",\n",
    "     \"25\":\"двадцать пятого\",\n",
    "     \"26\":\"двадцать шестого\",\n",
    "     \"27\":\"двадцать седьмого\",\n",
    "     \"28\":\"двадцать восьмого\",\n",
    "     \"29\":\"двадцать девятого\",\n",
    "     \"30\":\"тридцатого\",\n",
    "     \"31\":\"тридцать первого\",\n",
    "    }\n",
    "\n",
    "dd = {\"2\":\"двадцать\",\n",
    "      \"3\":\"тридцать\",\n",
    "      \"4\":\"сорок\",\n",
    "      \"5\":\"пятьдесят\",\n",
    "      \"6\":\"шестьдесят\",\n",
    "      \"7\":\"семьдесят\",\n",
    "      \"8\":\"восемьдесят\",\n",
    "      \"9\":\"девяносто\"\n",
    "     }\n",
    "\n",
    "dd0 = {\"1\":\"десятого\",\n",
    "       \"2\":\"двадцатого\",\n",
    "       \"3\":\"тридцатого\",\n",
    "       \"4\":\"сорокового\",\n",
    "       \"5\":\"пятидесятого\",\n",
    "       \"6\":\"шестидесятого\",\n",
    "       \"7\":\"семидесятого\",\n",
    "       \"8\":\"восьмидесятого\",\n",
    "       \"9\":\"девяностого\"\n",
    "     }\n",
    "\n",
    "ddd = {\"1\":\"сто\",\n",
    "       \"2\":\"двести\",\n",
    "       \"3\":\"триста\",\n",
    "       \"4\":\"четыреста\",\n",
    "       \"5\":\"пятьсот\",\n",
    "       \"6\":\"шестьсот\",\n",
    "       \"7\":\"семьсот\",\n",
    "       \"8\":\"восемьсот\",\n",
    "       \"9\":\"девятьсот\"\n",
    "     }\n",
    "\n",
    "gl = [\"a\",\"e\",\"u\",\"i\",\"o\",\"y\"]\n",
    "zv = [ \"b\" , \"v\" , \"g\" , \"d\" , \"z\" , \"l\" , \"m\" , \"n\" , \"r\" ]\n",
    "\n",
    "def thous(x):\n",
    "    if x[0]==\"1\":\n",
    "        res = \"тысяча \"\n",
    "    if x[0]==\"2\":\n",
    "        res = \"две тысячи \"\n",
    "    \n",
    "    if int(x[1])!=0:\n",
    "        res += ddd[x[1]]+\" \"\n",
    "    if int(x[2])>1:\n",
    "        if x[3]==\"0\":\n",
    "            res += dd0[x[2]] \n",
    "        else:\n",
    "            res += dd[x[2]]+\" \"+d[x[3]]\n",
    "    else:\n",
    "        if x[2]==\"0\":\n",
    "            res += d[x[3]]\n",
    "        else:\n",
    "            if x[3]==\"0\":\n",
    "                res += dd0[x[2]]\n",
    "            else:\n",
    "                res += d[x[2]+x[3]]\n",
    "        \n",
    "    return res + \" года\"\n",
    "\n",
    "def year(q):\n",
    "    res = \"\"\n",
    "    \n",
    "    for x in res_upd:\n",
    "        if x[2].endswith(q):\n",
    "            try:\n",
    "                y = x[2].split()[-3]\n",
    "                z = list(res_upd[x])[0]\n",
    "                res = z.split(y)[-1]\n",
    "                break\n",
    "            except:\n",
    "                pass\n",
    "        if q == x[2]:\n",
    "            try:\n",
    "                res = \" \"+list(res_upd[x])[0]\n",
    "                break\n",
    "            except:\n",
    "                pass\n",
    "    if res == \"\" and int(q[0])<3 and q[3]!=\"\":\n",
    "        try:\n",
    "            res = thous(q[:4])\n",
    "        except:\n",
    "            pass\n",
    "    return res\n",
    "\n",
    "def full_date(t):\n",
    "    a = {'г','г.','гг.'}\n",
    "    b = {'год','года','году'}\n",
    "    ans = \"\"\n",
    "    s = t.split()\n",
    "    if len(s) == 3 and len(s[-1])==4 and s[-1].isnumeric():\n",
    "        if s[0] in d:\n",
    "            res = year(s[2] + \" года\")\n",
    "            tmp = d[s[0]]+ \" \" + s[1] + res\n",
    "            if res != \"\":\n",
    "                ans = tmp\n",
    "            else:\n",
    "                print(s[2])\n",
    "    if len(s) == 4 and s[-1] in a|b:\n",
    "        if s[0] in d:\n",
    "            res = year(s[2] + \" \" + s[-1])\n",
    "            tmp = d[s[0]]+ \" \" + s[1] + res\n",
    "            if res != \"\":\n",
    "                ans = tmp\n",
    "            else:\n",
    "                print(s[2])\n",
    "    return ans\n",
    "\n",
    "def space_date(t):\n",
    "    t = t.replace(\" года\",'')\n",
    "    ans = \"\"\n",
    "    s = t.split()\n",
    "    if len(s) == 3 and len(s[-1])==4 and s[2].isnumeric() and s[0].isnumeric() and not s[1].isnumeric():\n",
    "        try:\n",
    "            ans = (d[s[0]][:-2]+\"е \").replace(\"ее\",'е') +  s[1] + \" \" + thous(s[2])\n",
    "        except:\n",
    "            pass\n",
    "    return ans\n",
    "\n",
    "def dot_date(t):\n",
    "    res = \"\"\n",
    "    s = t.split(\".\")\n",
    "    if len(s)!=3:\n",
    "        s = t.split(\"-\")\n",
    "        if len(s)!=3:\n",
    "            s = t.split(\"/\")\n",
    "            if len(s)!=3:\n",
    "                return \"\"\n",
    "    \n",
    "    if len(s[2]) == 2:\n",
    "        s[2] = \"19\"+s[2]\n",
    "    if len(s[2])!=4:\n",
    "        return \"\"\n",
    "        \n",
    "    if  len(s)==3 and s[0].isnumeric() and s[1].isnumeric() and s[2].isnumeric():\n",
    "        try:\n",
    "            res = (d[s[0]][:-2]+\"е \").replace(\"ее\",'е') +  mm[s[1]] + \" \" + thous(s[2])\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "    return res\n",
    "\n",
    "def hasNumbers(inputString):\n",
    "    return bool(re.search(r'\\d', inputString))\n",
    "\n",
    "def save_obj(obj, name):\n",
    "    with open('obj/'+ name + '.pkl', 'wb') as f:\n",
    "        pickle.dump(obj, f, -1)\n",
    "\n",
    "def load_obj(name):\n",
    "    with open('obj/' + name + '.pkl', 'rb') as f:\n",
    "        return pickle.load(f)\n",
    "\n",
    "def insert_key(key, arr, k = 1):\n",
    "    #if hasNumbers(arr): #no_digits\n",
    "    #    return\n",
    "    if key not in res_new:\n",
    "        res_new[key] = {arr : k}\n",
    "    else:\n",
    "        if arr in res_new[key]:\n",
    "            res_new[key][arr] += k\n",
    "        else:\n",
    "            res_new[key][arr] = k  \n",
    "            \n",
    "def is_ascii(s):\n",
    "    return all(ord(c) < 128 for c in s)\n",
    "\n",
    "def name_num(t):\n",
    "    if len(t) == 0:\n",
    "        return \"\"\n",
    "    while t[0]==\"0\":\n",
    "        return \"ноль \" + name_num(t[1:])\n",
    "        \n",
    "    if len(t) == 4:\n",
    "        if t[:2] == \"20\" and t[2]!=\"0\":\n",
    "            return \"двадцать \" + num2words(t[2:], lang='ru') + \" \"\n",
    "        if t[1]==\"0\" or t[2]==\"0\":\n",
    "            return num2words(t, lang='ru') + \" \"\n",
    "        return num2words(t[:2], lang='ru') + \" \" + num2words(t[2:], lang='ru') + \" \"\n",
    "    if len(t) <= 3:\n",
    "        num2words(t, lang='ru')\n",
    "    return num2words(t[:3], lang='ru') + \" \" + name_num(t[3:])\n",
    "\n",
    "def dash_num(t):\n",
    "    res = \"\"\n",
    "    s = t.split(\"-\")\n",
    "    for x in s:\n",
    "        res += name_num(x) + \"sil \"\n",
    "    return res[:-5]\n",
    "\n",
    "def url(x):\n",
    "    s = x.split(\"/\")\n",
    "    if len(s) == 2 and s[0].isnumeric() and s[1].isnumeric():\n",
    "        res = num2words(s[0], lang='ru') + \" \" + num2words(s[1], lang='ru')\n",
    "        if last:\n",
    "            if res.endswith(\"один\"):\n",
    "                res = res.replace(\"один\",\"первых\")\n",
    "            elif res.endswith(\"два\"):\n",
    "                res = res.replace(\"два\",\"вторых\")\n",
    "            elif res.endswith(\"три\"):\n",
    "                res = res.replace(\"три\",\"третьих\")\n",
    "            elif res.endswith(\"четыре\"):\n",
    "                res = res.replace(\"четыре\",\"четвертых\")\n",
    "            elif res.endswith(\"семь\"):\n",
    "                res = res.replace(\"семь\",\"седьмых\")\n",
    "            elif res.endswith(\"восемь\"):\n",
    "                res = res.replace(\"восемь\",\"восьмых\")\n",
    "            elif res.endswith(\"сто\"):\n",
    "                res = res.replace(\"сто\",\"сотых\")\n",
    "            else:\n",
    "                res = res[:-1] + \"ых\"\n",
    "            return res\n",
    "\n",
    "    res = \"\"\n",
    "    if x.startswith(\"http://www.\"):\n",
    "        res = \"h t t p w w w точка \"\n",
    "        x = x.replace(\"http://www.\", \"\")\n",
    "    elif x.startswith(\"http://\"):\n",
    "        res = \"h t t p \"\n",
    "        x = x.replace(\"http://\", \"\")\n",
    "    \n",
    "    ss = x.split(\"/\")\n",
    "    #print(ss)\n",
    "    i = 0\n",
    "    for z in ss:\n",
    "        if z == \"\":\n",
    "            continue\n",
    "        s = z.split(\".\")\n",
    "        #print(s)\n",
    "        for y in s:\n",
    "            if y ==\"\":\n",
    "                continue\n",
    "            if y.isnumeric():\n",
    "                res += num2words(y, lang='ru') + \" точка \"\n",
    "            elif not y.isalpha() or not is_ascii(y):\n",
    "                #print(y)\n",
    "                return \"\"\n",
    "            else:\n",
    "                res += trans(y) + \" точка \" \n",
    "        res = res[:-7] + \" косая черта \"\n",
    "    if x[-1] == \"/\":\n",
    "        res += \" косая черта\"\n",
    "    res = res[:-13]\n",
    "    return res\n",
    "\n",
    "def trans(x):\n",
    "    if len(x)>1:\n",
    "        if x in s:\n",
    "            return s[x]\n",
    "        \n",
    "        key = (None, None, x, None, None)\n",
    "        if key in res_upd:\n",
    "            srtd = sorted(res_upd[key].items(), key=operator.itemgetter(1), reverse=True)\n",
    "            t = srtd[0][0]\n",
    "            return t\n",
    "    \n",
    "    word = x.lower()\n",
    "    t = (\"_trans \".join(translit(word, 'ru')) + \"_trans\")\n",
    "    t = t.replace(\"w_trans\",\"в_trans\")\n",
    "    t = t.replace(\"ы_trans\",\"и_trans\")\n",
    "    t = t.replace(\"щ_trans\",\"ш_trans\")\n",
    "    t = t.replace(\"ц_trans\",\"к_trans\")\n",
    "    t = t.replace(\"а_trans л_trans л_trans\",\"о_trans л_trans\")\n",
    "    t = t.replace(\"т_trans и_trans о_trans\",\"ш_trans е_trans\")\n",
    "    t = t.replace(\"и_trans е_trans в_trans\",\"ь_trans ю_trans\")\n",
    "    t = t.replace(\"т_trans у_trans р_trans\",\"ч_trans е_trans р_trans\")\n",
    "    t = t.replace(\"е_trans в_trans\",\"ь_trans ю_trans\")\n",
    "    t = t.replace(\"а_trans и_trans\",\"э_trans й_trans\")\n",
    "    t = t.replace(\"г_trans у_trans\",\"г_trans а_trans\")\n",
    "    t = t.replace(\"о_trans и_trans\",\"о_trans й_trans\")\n",
    "    t = t.replace(\"т_trans х_trans\",\"т_trans\")\n",
    "    t = t.replace(\"о_trans о_trans\",\"у_trans\")\n",
    "    t = t.replace(\"е_trans е_trans\",\"и_trans\")\n",
    "    t = t.replace(\"п_trans х_trans\",\"ф_trans\")\n",
    "    t = t.replace(\"с_trans ч_trans\",\"ш_trans\")\n",
    "    t = t.replace(\"а_trans у_trans\",\"о_trans\")\n",
    "    t = t.replace(\"о_trans а_trans\",\"о_trans\")\n",
    "    t = t.replace(\"в_trans х_trans\",\"у_trans\")\n",
    "    t = t.replace(\"к_trans к_trans\",\"к_trans\")\n",
    "    t = t.replace(\"х_trans н_trans\",\"н_trans\")\n",
    "    t = t.replace(\"х_trans л_trans\",\"л_trans\")\n",
    "    t = t.replace(\"х_trans р_trans\",\"р_trans\")\n",
    "    t = t.replace(\"х_trans к_trans\",\"к_trans\")\n",
    "    t = t.replace(\"x_trans\",\"к_trans с_trans\")\n",
    "    t = t.replace(\"х_trans у_trans\",\"х_trans а_trans\")\n",
    "    t = t.replace(\"е_trans и_trans\",\"е_trans й_trans\")\n",
    "    t = t.replace(\"с_trans у_trans\",\"с_trans а_trans\")\n",
    "    t = t.replace(\"п_trans у_trans\",\"п_trans а_trans\")\n",
    "    t = t.replace(\"г_trans и_trans я_trans\",\"д_trans ж_trans и_trans я_trans\")\n",
    "    t = t.replace(\"у_trans н_trans т_trans\",\"а_trans н_trans т_trans\")\n",
    "    t = t.replace(\"у_trans н_trans д_trans\",\"а_trans н_trans д_trans\")\n",
    "    t = t.replace(\"у_trans н_trans к_trans\",\"а_trans н_trans к_trans\")\n",
    "    t = t.replace(\"у_trans б_trans\",\"а_trans б_trans\")\n",
    "    t = t.replace(\"с_trans в_trans\",\"с_trans у_trans\")\n",
    "    #t = t.replace(\"к_trans у_trans\",\"с_trans у_trans\")\n",
    "\n",
    "    if t.endswith(\"е_trans\"):\n",
    "        t = t[:-8]\n",
    "\n",
    "    if t.endswith(\"г_trans у_trans\"):\n",
    "        t = t[:-8]\n",
    "\n",
    "    if t.startswith(\"е_trans\"):\n",
    "        t = \"э\" + t[1:]\n",
    "\n",
    "    if word[0] == \"w\" and len(word)>1:\n",
    "        t = \"у\" + t[1:]\n",
    "\n",
    "    if word[0] == \"j\" and len(word)>1:\n",
    "        tt = \"д_trans ж_trans\"\n",
    "        if word[1]==\"u\":\n",
    "            tt+=\" y_trans\"\n",
    "        if word[1]==\"a\":\n",
    "            tt+=\" е_trans\"\n",
    "        t = tt + t[7:]\n",
    "\n",
    "    #if word.startswith(\"wi\"):\n",
    "    #    t = \"в\" + t[1:]\n",
    "\n",
    "    if word.endswith(\"ts\") and t.endswith(\"к_trans\"):\n",
    "        t = t[:-8] + \" т_trans с_trans\"\n",
    "\n",
    "    if word.endswith(\"ux\"):\n",
    "        t = t[:-16]\n",
    "\n",
    "    if word.endswith(\"ge\") and t.endswith(\"г_trans\"):\n",
    "        t = t[:-8] + \" д_trans ж_trans\"\n",
    "\n",
    "    if t.startswith(\"а_trans и_trans р_trans\"):\n",
    "        t = \"а_trans й_trans\" + t[15:]\n",
    "\n",
    "    if t.endswith(\"и_trans а_trans\"):\n",
    "        t = t[:-8] + \" я_trans\"\n",
    "\n",
    "    if t.endswith(\"е_trans с_trans\") and not word.endswith(\"ses\") and not word.endswith(\"hes\"):\n",
    "        t = t[:-15] + \"с_trans\"\n",
    "\n",
    "    if t.endswith(\"д_trans г_trans\"):\n",
    "        t = t[:-8] + \" ж_trans\"\n",
    "\n",
    "    if len(word)>2 and word[0]=='c' and word[1]=='h' and word[2] not in gl:\n",
    "        t = \"к\" + t[1:]\n",
    "\n",
    "    if \"ce\" in word:\n",
    "        t = t.replace(\"к_trans\",\"с_trans\") \n",
    "\n",
    "    t = t.replace(\"у_trans н_trans д_trans\",\"а_trans н_trans д_trans\")\n",
    "    \n",
    "    return t    \n",
    "\n",
    "df = pd.read_csv(\"input/ru_test_2.csv\")\n",
    "print(df.head())\n",
    "print(df.tail())\n",
    "test_set_old = set(df.before)\n",
    "print(len(test_set_old))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.1 Build dict of different word meanings based on train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 10571822/10574517 [00:43<00:00, 270164.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "801234"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "          \r",
      "100%|█████████▉| 10571822/10574517 [01:00<00:00, 176043.23it/s]"
     ]
    }
   ],
   "source": [
    "#1 min \n",
    "train = open(os.path.join(INPUT_PATH, \"ru_train.csv\"), encoding='UTF8')\n",
    "line = train.readline()\n",
    "res_new = dict()\n",
    "last = \"\"\n",
    "for i in tqdm(range(10574517)):\n",
    "    line = train.readline().strip()\n",
    "    if line == '':\n",
    "        print(\"Finish\")\n",
    "        break\n",
    "    \n",
    "    pos = line.find('\",\"')\n",
    "    text = line[pos + 2:]\n",
    "    if text[:3] == '\",\"':\n",
    "        continue\n",
    "    text = text[1:-1]\n",
    "    arr = text.split('\",\"')\n",
    "    \n",
    "    insert_key(arr[0], arr[1])\n",
    "    \n",
    "train.close()\n",
    "gc.collect()\n",
    "len(res_new)\n",
    "#801234"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#save_obj(res_new, \"word_meanings_dict_train\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.2 The same for external data set# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████| 100/100 [17:28<00:00, 11.21s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4922825"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#18 min \n",
    "res_new = load_obj(\"word_meanings_dict_train\") \n",
    "\n",
    "files = os.listdir(DATA_INPUT_PATH)\n",
    "for file in tqdm(files):\n",
    "    train = open(os.path.join(DATA_INPUT_PATH, file), encoding='UTF8')\n",
    "    while 1:\n",
    "        line = train.readline().strip()\n",
    "        if line == '':\n",
    "            break\n",
    "        \n",
    "        pos = line.find('\\t')\n",
    "        text = line[pos + 1:]\n",
    "        if text[:3] == '':\n",
    "            continue\n",
    "        arr = text.split('\\t')\n",
    "        if arr[0] == '<eos>':\n",
    "            continue\n",
    "        \n",
    "        if arr[1] == '<self>' or arr[1] == 'sil':\n",
    "            arr[1] = arr[0]\n",
    "    \n",
    "        insert_key(arr[0], arr[1])\n",
    "        \n",
    "    train.close()\n",
    "    gc.collect()\n",
    "len(res_new)\n",
    "#4922825"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#save_obj(res_new, \"word_meanings_dict_all\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Produce single/multi meaning word sets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4835693\n",
      "153976\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 106815/153976 [00:00<00:00, 520124.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 153976/153976 [00:00<00:00, 534343.64it/s]\n"
     ]
    }
   ],
   "source": [
    "#10 sec\n",
    "res_new = load_obj(\"word_meanings_dict_all\") \n",
    "res = [x for x in res_new if len(res_new[x])==1]\n",
    "print(len(res))\n",
    "\n",
    "single = set(res) & test_set_old\n",
    "print(len(single))\n",
    "\n",
    "multi_words = list(test_set_old-set(res)-punct-dash-short)\n",
    "print(len(multi_words))\n",
    "\n",
    "s = dict()\n",
    "for x in tqdm(single):\n",
    "    s[x] = list(res_new[x])[0]\n",
    "    \n",
    "#4835693\n",
    "#153976\n",
    "#22001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#save_obj(s, \"single_meaning_words\")  \n",
    "#save_obj(multi_words, \"multi_meaning_words\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Make 5 word seq dict for test set (multi meaning) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 72692/72692 [00:12<00:00, 5659.18it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "462131"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#10 sec\n",
    "test_set = set()\n",
    "\n",
    "multi_words = load_obj(\"multi_meaning_words\") \n",
    "\n",
    "df = pd.read_csv(\"input/ru_test_2.csv\")\n",
    "dp = df[df.before.isin(multi_words)] \n",
    "\n",
    "before = df.before\n",
    "token = df.token_id\n",
    "\n",
    "for i in tqdm(dp.index):\n",
    "    arr = before[i]\n",
    "    \n",
    "    try:\n",
    "        if token[i-1] == 0:\n",
    "            lost = \"\"\n",
    "        else:\n",
    "            lost = before[i-2]\n",
    "    except:\n",
    "        lost = \"\"\n",
    "        \n",
    "    try:\n",
    "        if token[i] == 0:\n",
    "            last = \"\"\n",
    "        else:\n",
    "            last = before[i-1]\n",
    "    except:\n",
    "        last = \"\"\n",
    "    \n",
    "    if last==\"\":\n",
    "        lost=\"\"\n",
    "        \n",
    "    try:\n",
    "        if token[i+1]==0:\n",
    "            nex = \"\"\n",
    "        else:\n",
    "            nex = before[i+1]\n",
    "    except:\n",
    "        nex = \"\"\n",
    "        \n",
    "    try:\n",
    "        if token[i+2]==0:\n",
    "            nexx = \"\"\n",
    "        else:\n",
    "            nexx = before[i+2]\n",
    "    except:\n",
    "        nexx = \"\"\n",
    "    if nex==\"\":\n",
    "        nexx=\"\"\n",
    "    \n",
    "    for key in [(lost, last, arr, nex, nexx),\n",
    "                \n",
    "                (lost, last, arr, nex, None),\n",
    "                (None, last, arr, nex, nexx),\n",
    "                \n",
    "                (lost, last, arr, None, None),\n",
    "                (None, last, arr, nex, None),\n",
    "                (None, None, arr, nex, nexx),\n",
    "                \n",
    "                (None, last, arr, None, None), \n",
    "                (None, None, arr, nex, None),\n",
    "                \n",
    "                (None, None, arr, None, None)]:\n",
    "        test_set.add(key)\n",
    "len(test_set)\n",
    "#462131"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#save_obj(test_set, \"multi_seq_test\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.1 Build freq dict for train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 461864/461864 [01:55<00:00, 4001.49it/s]\n",
      "  1%|          | 11011/2157638 [00:00<00:35, 59750.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108578\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2157638/2157638 [00:03<00:00, 651184.55it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "108578"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#2 min\n",
    "test_set = load_obj(\"multi_seq_test\")\n",
    "multi_words = load_obj(\"multi_meaning_words\")\n",
    "\n",
    "res_new = dict()\n",
    "big_set = set()\n",
    "big_dict = dict()\n",
    "\n",
    "df = pd.read_csv(\"input/ru_train.csv\")\n",
    "dp = df[df.before.isin(multi_words)] \n",
    "\n",
    "before = df.before\n",
    "after = df.after\n",
    "token = df.token_id\n",
    "\n",
    "for i in tqdm(dp.index):\n",
    "    arr = [before[i], after[i]]\n",
    "    \n",
    "    try:\n",
    "        if token[i-1] == 0:\n",
    "            lost = \"\"\n",
    "        else:\n",
    "            lost = before[i-2]\n",
    "    except:\n",
    "        lost = \"\"\n",
    "        \n",
    "    try:\n",
    "        if token[i] == 0:\n",
    "            last = \"\"\n",
    "        else:\n",
    "            last = before[i-1]\n",
    "    except:\n",
    "        last = \"\"\n",
    "    \n",
    "    if last==\"\":\n",
    "        lost=\"\"\n",
    "        \n",
    "    try:\n",
    "        if token[i+1]==0:\n",
    "            nex = \"\"\n",
    "        else:\n",
    "            nex = before[i+1]\n",
    "    except:\n",
    "        nex = \"\"\n",
    "        \n",
    "    try:\n",
    "        if token[i+2]==0:\n",
    "            nexx = \"\"\n",
    "        else:\n",
    "            nexx = before[i+2]\n",
    "    except:\n",
    "        nexx = \"\"\n",
    "    if nex==\"\":\n",
    "        nexx=\"\"        \n",
    "    \n",
    "    for key in [(lost, last, arr[0], nex, nexx),\n",
    "                \n",
    "                (lost, last, arr[0], nex, None),\n",
    "                (None, last, arr[0], nex, nexx),\n",
    "                \n",
    "                (lost, last, arr[0], None, None),\n",
    "                (None, last, arr[0], nex, None),\n",
    "                (None, None, arr[0], nex, nexx),\n",
    "                \n",
    "                (None, last, arr[0], None, None), \n",
    "                (None, None, arr[0], nex, None),\n",
    "                \n",
    "                (None, None, arr[0], None, None)]:\n",
    "        big_set.add(key)\n",
    "        try:\n",
    "            big_dict[(key, arr[1])]+= 1\n",
    "        except:\n",
    "            big_dict[(key, arr[1])] = 1\n",
    "            \n",
    "inter = big_set & test_set\n",
    "print(len(inter))\n",
    "for key, arr in tqdm(list(big_dict)):\n",
    "    if key in inter:\n",
    "        insert_key(key, arr, big_dict[(key, arr)])\n",
    "\n",
    "len(res_new)\n",
    "#108578"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#save_obj(res_new, \"freq_dict_train\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.2 The same for external data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [1:00:26<00:00, 44.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "207820\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#1 hour\n",
    "test_set = load_obj(\"multi_seq_test\")\n",
    "res_new = load_obj(\"freq_dict_train\") \n",
    "multi_words = load_obj(\"multi_meaning_words\")\n",
    "\n",
    "files = os.listdir(DATA_INPUT_PATH)\n",
    "for file in tqdm(files):\n",
    "    df = pd.read_csv(DATA_INPUT_PATH+\"/\"+file, sep=\"\\t\", low_memory = False, error_bad_lines = False, quoting=3)\n",
    "    df.columns = [0,1,2]\n",
    "    \n",
    "    dp = df[df[1].isin(multi_words)] \n",
    "    \n",
    "    before = df[1]\n",
    "    after = df[2]\n",
    "    \n",
    "    big_set = set()\n",
    "    big_dict = dict()\n",
    "    \n",
    "    for i in dp.index:\n",
    "        arr = [before[i], after[i]]\n",
    "        if arr[1] == '<self>' or arr[1] == 'sil':\n",
    "            arr[1] = arr[0]\n",
    "        \n",
    "        try:\n",
    "            if before[i-2]==\"<eos>\":\n",
    "                lost = \"\"\n",
    "            else:\n",
    "                lost = before[i-2]\n",
    "        except:\n",
    "            lost = \"\"\n",
    "        \n",
    "        try:\n",
    "            if before[i-1]==\"<eos>\":\n",
    "                last = \"\"\n",
    "            else:\n",
    "                last = before[i-1]\n",
    "        except:\n",
    "            last = \"\"\n",
    "            \n",
    "        if last==\"\":\n",
    "            lost=\"\"\n",
    "            \n",
    "        try:\n",
    "            if before[i+1]==\"<eos>\":\n",
    "                nex = \"\"\n",
    "            else:\n",
    "                nex = before[i+1]\n",
    "        except:\n",
    "            nex = \"\"\n",
    "        try:\n",
    "            if before[i+2]==\"<eos>\":\n",
    "                nexx = \"\"\n",
    "            else:\n",
    "                nexx = before[i+2]\n",
    "        except:\n",
    "            nexx = \"\"\n",
    "        if nex==\"\":\n",
    "            nexx=\"\"\n",
    "        \n",
    "        for key in [(lost, last, arr[0], nex, nexx),\n",
    "                \n",
    "                    (lost, last, arr[0], nex, None),\n",
    "                    (None, last, arr[0], nex, nexx),\n",
    "\n",
    "                    (lost, last, arr[0], None, None),\n",
    "                    (None, last, arr[0], nex, None),\n",
    "                    (None, None, arr[0], nex, nexx),\n",
    "\n",
    "                    (None, last, arr[0], None, None), \n",
    "                    (None, None, arr[0], nex, None),\n",
    "\n",
    "                    (None, None, arr[0], None, None)]:\n",
    "            \n",
    "            big_set.add(key)\n",
    "            try:\n",
    "                big_dict[(key, arr[1])]+= 1\n",
    "            except:\n",
    "                big_dict[(key, arr[1])] = 1\n",
    "    \n",
    "    inter = big_set & test_set\n",
    "    for key, arr in list(big_dict):\n",
    "        if key in inter:\n",
    "            insert_key(key, arr, big_dict[(key, arr)])\n",
    "print(len(res_new))\n",
    "#207820\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#save_obj(res_new, \"freq_dict_all\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. main loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 814453/989880 [03:03<00:55, 3151.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0201\n",
      "0201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 843498/989880 [03:08<00:28, 5120.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "701\n",
      "701\n",
      "701\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████ | 898289/989880 [03:20<00:28, 3208.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "676\n",
      "676\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 989880/989880 [03:39<00:00, 4505.69it/s]\n"
     ]
    }
   ],
   "source": [
    "#4 min\n",
    "res_upd  = load_obj(\"freq_dict_all\")\n",
    "s = load_obj(\"single_meaning_words\")\n",
    "\n",
    "multi_new = set()\n",
    "multi_upd = list()\n",
    "single_set = set()\n",
    "\n",
    "df = pd.read_csv(\"input/ru_test_2.csv\")\n",
    "\n",
    "before = df.before\n",
    "token = df.token_id\n",
    "sentence = df.sentence_id\n",
    "\n",
    "ides = list()\n",
    "after = list()\n",
    "reason = list()\n",
    "\n",
    "for i in tqdm(range(len(df))):\n",
    "    arr = before[i]\n",
    "    i1 = sentence[i]\n",
    "    i2 = token[i]\n",
    "    \n",
    "    ides.append(str(i1) + '_' + str(i2))\n",
    "    \n",
    "    try:\n",
    "        if token[i-1] == 0:\n",
    "            lost = \"\"\n",
    "        else:\n",
    "            lost = before[i-2]\n",
    "    except:\n",
    "        lost = \"\"\n",
    "        \n",
    "    try:\n",
    "        if token[i] == 0:\n",
    "            last = \"\"\n",
    "        else:\n",
    "            last = before[i-1]\n",
    "    except:\n",
    "        last = \"\"\n",
    "    \n",
    "    if last==\"\":\n",
    "        lost=\"\"\n",
    "        \n",
    "    try:\n",
    "        if token[i+1]==0:\n",
    "            nex = \"\"\n",
    "        else:\n",
    "            nex = before[i+1]\n",
    "    except:\n",
    "        nex = \"\"\n",
    "        \n",
    "    try:\n",
    "        if token[i+2]==0:\n",
    "            nexx = \"\"\n",
    "        else:\n",
    "            nexx = before[i+2]\n",
    "    except:\n",
    "        nexx = \"\"\n",
    "    if nex==\"\":\n",
    "        nexx=\"\"\n",
    "    \n",
    "    #check if word has single meaning\n",
    "    if arr in s: \n",
    "        tmp = s[arr]\n",
    "        q=0\n",
    "    #punctuation or short word wit almost unique meaning \n",
    "    elif arr in punct or arr in short:\n",
    "        tmp = arr\n",
    "        q=1\n",
    "    #special case of dash usage\n",
    "    elif arr in dash:\n",
    "        if before[i-2] == \"от\" and lost!=\"\":\n",
    "            tmp = \"до\"\n",
    "            q=3\n",
    "        else:\n",
    "            tmp = arr\n",
    "            q=2\n",
    "    #5 word sequences\n",
    "    else:\n",
    "        found = False\n",
    "        q = 1\n",
    "        for key in [(lost, last, arr, nex, nexx),\n",
    "                \n",
    "                    (lost, last, arr, nex, None),\n",
    "                    (None, last, arr, nex, nexx),\n",
    "\n",
    "                    (lost, last, arr, None, None),\n",
    "                    (None, last, arr, nex, None),\n",
    "                    (None, None, arr, nex, nexx),\n",
    "\n",
    "                    (None, last, arr, None, None), \n",
    "                    (None, None, arr, nex, None),\n",
    "\n",
    "                    (None, None, arr, None, None)\n",
    "                   ]:\n",
    "\n",
    "            if key in res_upd:\n",
    "                srtd = sorted(res_upd[key].items(), key=operator.itemgetter(1), reverse=True)\n",
    "                \n",
    "                #in case of multiple meanings\n",
    "                if len(srtd)>1:\n",
    "                    \n",
    "                    #check first date format \n",
    "                    tmp = space_date(arr)\n",
    "                    if tmp !=\"\" and last.lower() in space|{\",\",\"—\",'('}:\n",
    "                        found = True\n",
    "                        q = -22\n",
    "                        break\n",
    "                    \n",
    "                    #check second date format \n",
    "                    tmp = full_date(arr)\n",
    "                    if tmp !=\"\" and last.lower() in full:\n",
    "                        found = True\n",
    "                        q = -21\n",
    "                        break\n",
    "                    \n",
    "                tmp = srtd[0][0]\n",
    "                found = True\n",
    "                q*=10\n",
    "                                \n",
    "                break\n",
    "            q+=1\n",
    "        if not found:\n",
    "            #NaN\n",
    "            if str(arr) == \"nan\":\n",
    "                tmp = \"н_trans а_trans н_trans\" #\"n a\" \n",
    "                q = 0\n",
    "            else:\n",
    "                #check first date format \n",
    "                if last.lower() in space|{\",\",\"—\",'('}:\n",
    "                    tmp = space_date(arr)\n",
    "                    q = -1.2\n",
    "                #check second date format \n",
    "                else:    \n",
    "                    tmp = full_date(arr)\n",
    "                    q = -1.1\n",
    "                if tmp==\"\":\n",
    "                    #check trird date format \n",
    "                    ar = arr.replace(\" г.\", '').replace(\" года\", '')\n",
    "                    tmp = dot_date(ar)\n",
    "                    q=-10\n",
    "                    if tmp==\"\":\n",
    "                        #long number\n",
    "                        if len(arr)>10 and arr.isnumeric():\n",
    "                            tmp = \" \".join([ch[x] for x in arr])\n",
    "                            q=-7\n",
    "                        else:\n",
    "                            #$ at the beginning\n",
    "                            if arr[0] == \"$\":\n",
    "                                arr = arr[1:] + \" $\"\n",
    "                            l = []\n",
    "                            \n",
    "                            #remove spaces between numbers\n",
    "                            spl = arr.split(\" \")\n",
    "                            if len(spl)>1:\n",
    "                                ar = ''\n",
    "                                for i in range(len(spl)):\n",
    "                                    ar += spl[i]\n",
    "                                    if i+1 < len(spl):\n",
    "                                        if not spl[i].isnumeric() or not spl[i+1].isnumeric():\n",
    "                                            ar += \" \"\n",
    "                                arr = ar\n",
    "                            \n",
    "                            #split into separate words\n",
    "                            for word in arr.split(\" \"):\n",
    "                                key = (None, None, word, None, None)\n",
    "                                if key in res_upd:\n",
    "                                    srtd = sorted(res_upd[key].items(), key=operator.itemgetter(1), reverse=True)\n",
    "                                    t = srtd[0][0]\n",
    "                                    q = -2\n",
    "                                    if len(srtd)>1:\n",
    "                                        p = space_date(word)\n",
    "                                        if p !=\"\" and last.lower() in space|{\",\",\"—\",'('}:\n",
    "                                            q = -24\n",
    "                                            t = p\n",
    "\n",
    "                                        p = full_date(arr)\n",
    "                                        if p !=\"\" and last.lower() in full:\n",
    "                                            q = -23\n",
    "                                            t = p\n",
    "                                    \n",
    "                                    l.append(t)\n",
    "                                else:\n",
    "                                    #custom endings\n",
    "                                    if word in m:\n",
    "                                        l.append(m[word])\n",
    "                                    elif word.replace(\".\",\"\") in m:\n",
    "                                        l.append(m[word.replace(\".\",\"\")])\n",
    "                                    elif is_ascii(word):\n",
    "                                        #eng word\n",
    "                                        if word.isalpha():\n",
    "                                            t = trans(word)\n",
    "                                            l.append(t)\n",
    "                                            q = -3\n",
    "                                        else:\n",
    "                                            try:\n",
    "                                                #number\n",
    "                                                l.append(num2words(word, lang='ru'))\n",
    "                                                q = -4\n",
    "                                            except:\n",
    "                                                try:\n",
    "                                                    l.append(num2words(word.translate(SUB).translate(SUP), lang='ru'))\n",
    "                                                    q = -4\n",
    "                                                except:\n",
    "                                                    #number like 123-12314-52345\n",
    "                                                    if (word.count(\"-\")>0 and word.count(\".\")==0 \n",
    "                                                        and word.count(\"/\")==0 and word.count(\"(\")==0\n",
    "                                                        and word.count(\"B\")==0):\n",
    "\n",
    "                                                        l.append(dash_num(word.replace(\" \",\"-\")).replace(\"одна \",\"\"))\n",
    "                                                        q=-50\n",
    "                                                    else:\n",
    "                                                        l.append(word)\n",
    "                                                        q = -5\n",
    "\n",
    "                                    else:\n",
    "                                        try:\n",
    "                                            #number\n",
    "                                            l.append(num2words(word, lang='ru'))\n",
    "                                            q = -4\n",
    "                                        except:\n",
    "                                            #if nothing works leave the word as is\n",
    "                                            l.append(word)\n",
    "                                            q = -6\n",
    "                            tmp = \" \".join(l) \n",
    "                            single_set.add(((lost, last, arr, nex, nexx),i))\n",
    "\n",
    "    #external set was inconsistent with train set\n",
    "    if \"_letter_latin\" in tmp:\n",
    "        t = tmp\n",
    "        tmp = tmp.replace(\"_letter_latin\", \"_latin\")\n",
    "        q+=1000\n",
    "        multi_new.add((t,tmp))\n",
    "    \n",
    "    if tmp[0] == \" \":\n",
    "        tmp = tmp[1:]\n",
    "    \n",
    "    #special case of url\n",
    "    if q == -5:\n",
    "        x = arr\n",
    "        t = url(arr)\n",
    "        if t!=\"\":\n",
    "            tmp = t\n",
    "            q = -13\n",
    "    \n",
    "    after.append(tmp)\n",
    "    reason.append(q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Save prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18 0 11951\n"
     ]
    }
   ],
   "source": [
    "#10 sec\n",
    "dic = {\"id\": ides, \"after\": after, \"type\": reason}\n",
    "dr = pd.DataFrame(data=dic)\n",
    "dr.to_csv(\"baseline_ext_rus_my.csv\", sep=\",\", index=False, quoting=csv.QUOTE_ALL, columns=[\"id\",\"after\"])\n",
    "\n",
    "print(len(multi_new),len(multi_upd), len(single_set))\n",
    "#dr.type.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Compare to final solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no diff\n"
     ]
    }
   ],
   "source": [
    "#1 sec\n",
    "dc = pd.read_csv(\"baseline_ext_rus_my_9926.csv\")\n",
    "dc.head()\n",
    "\n",
    "dc[\"new\"] = dr[\"after\"]\n",
    "if len(dc[dc[\"after\"] != dc[\"new\"]])==0:\n",
    "    print(\"no diff\")"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
